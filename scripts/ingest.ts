#!/usr/bin/env tsx
/**
 * Mexican Law MCP — Ingestion Pipeline
 *
 * Fetches Mexican federal legislation from Cámara de Diputados (diputados.gob.mx).
 * Downloads DOC files (preferred) or PDF files (fallback) for each law and parses
 * the structured content into provision-level JSON seed files.
 *
 * **Census-driven**: Reads data/census.json (generated by scripts/census.ts) to
 * enumerate ALL federal laws. Falls back to KEY_MEXICAN_ACTS if census is missing.
 *
 * Usage:
 *   npm run ingest                    # Full ingestion (from census)
 *   npm run ingest -- --limit 5       # Test with 5 laws
 *   npm run ingest -- --skip-fetch    # Reuse cached pages
 *   npm run ingest -- --resume        # Skip laws that already have seed files
 *
 * Mexican legislation is public domain as government publication.
 */

import * as fs from 'fs';
import * as path from 'path';
import { fileURLToPath } from 'url';
import { fetchLawFile, docToText, pdfToText } from './lib/fetcher.js';
import { parseMexicanText, KEY_MEXICAN_ACTS, type LawIndexEntry, type ParsedLaw } from './lib/parser.js';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const SOURCE_DIR = path.resolve(__dirname, '../data/source');
const SEED_DIR = path.resolve(__dirname, '../data/seed');
const CENSUS_PATH = path.resolve(__dirname, '../data/census.json');

interface CensusLaw {
  id: string;
  code: string;
  title: string;
  titleEn: string;
  shortName: string;
  category: string;
  url: string;
  pdfUrl: string;
  docUrl?: string;
  classification: 'ingestable' | 'inaccessible' | 'metadata_only';
}

interface CensusData {
  generated_at: string;
  stats: { total: number; class_ingestable: number; class_inaccessible: number; class_metadata_only: number };
  laws: CensusLaw[];
}

function parseArgs(): { limit: number | null; skipFetch: boolean; resume: boolean } {
  const args = process.argv.slice(2);
  let limit: number | null = null;
  let skipFetch = false;
  let resume = false;

  for (let i = 0; i < args.length; i++) {
    if (args[i] === '--limit' && args[i + 1]) {
      limit = parseInt(args[i + 1], 10);
      i++;
    } else if (args[i] === '--skip-fetch') {
      skipFetch = true;
    } else if (args[i] === '--resume') {
      resume = true;
    }
  }

  return { limit, skipFetch, resume };
}

/**
 * Convert a census law entry into the LawIndexEntry format used by the parser.
 */
function censusLawToIndexEntry(censusLaw: CensusLaw): LawIndexEntry {
  return {
    id: censusLaw.id,
    code: censusLaw.code,
    title: censusLaw.title,
    titleEn: censusLaw.titleEn || undefined,
    shortName: censusLaw.shortName,
    status: 'in_force',
    issuedDate: '',
    inForceDate: '',
    url: censusLaw.url,
    pdfUrl: censusLaw.pdfUrl || undefined,
    docUrl: censusLaw.docUrl || undefined,
    description: censusLaw.title,
  };
}

/**
 * Load laws from census.json if available, otherwise fall back to KEY_MEXICAN_ACTS.
 */
function loadLawList(): LawIndexEntry[] {
  if (fs.existsSync(CENSUS_PATH)) {
    const raw = fs.readFileSync(CENSUS_PATH, 'utf-8');
    const census = JSON.parse(raw) as CensusData;

    console.log(`  Census: ${census.stats.total} laws (generated ${census.generated_at})`);

    // Only include ingestable laws
    const ingestable = census.laws.filter(a => a.classification === 'ingestable');
    console.log(`  Ingestable: ${ingestable.length} laws`);

    return ingestable.map(censusLawToIndexEntry);
  }

  console.log('  WARNING: No census.json found — falling back to KEY_MEXICAN_ACTS (10 laws)');
  console.log('  Run: npx tsx scripts/census.ts   to generate full census\n');
  return KEY_MEXICAN_ACTS;
}

/**
 * Create a fallback seed with law metadata when fetching fails.
 * This ensures the database always has the law entries even if the
 * upstream source is unreachable.
 */
function createFallbackSeed(law: LawIndexEntry): ParsedLaw {
  return {
    id: law.id,
    type: 'statute',
    title: law.title,
    title_en: law.titleEn,
    short_name: law.shortName,
    status: law.status,
    issued_date: law.issuedDate,
    in_force_date: law.inForceDate,
    url: law.url,
    description: law.description ?? law.title,
    provisions: [
      {
        provision_ref: 'art1',
        section: '1',
        title: `${law.shortName} - Artículo 1`,
        content: `${law.title}. ${law.description ?? ''}. Texto completo disponible en: ${law.url}`,
      },
    ],
    definitions: [],
  };
}

async function fetchAndParseLaws(laws: LawIndexEntry[], skipFetch: boolean, resume: boolean): Promise<void> {
  console.log(`\nProcessing ${laws.length} federal laws...\n`);

  fs.mkdirSync(SOURCE_DIR, { recursive: true });
  fs.mkdirSync(SEED_DIR, { recursive: true });

  let processed = 0;
  let skipped = 0;
  let resumed = 0;
  let failed = 0;
  let fallbacks = 0;
  let totalProvisions = 0;
  let totalDefinitions = 0;
  let docCount = 0;
  let pdfCount = 0;
  const startTime = Date.now();

  const report: { law: string; provisions: number; definitions: number; status: string }[] = [];

  for (const law of laws) {
    const sourceFile = path.join(SOURCE_DIR, `${law.id}.txt`);
    const seedFile = path.join(SEED_DIR, `${law.id}.json`);

    // Resume support: skip laws that already have seed files
    if (resume && fs.existsSync(seedFile)) {
      const existing = JSON.parse(fs.readFileSync(seedFile, 'utf-8')) as ParsedLaw;
      totalProvisions += existing.provisions.length;
      totalDefinitions += existing.definitions.length;
      resumed++;
      processed++;
      continue;
    }

    // Skip if seed already exists and we're in skip-fetch mode
    if (skipFetch && fs.existsSync(seedFile)) {
      const existing = JSON.parse(fs.readFileSync(seedFile, 'utf-8')) as ParsedLaw;
      report.push({
        law: law.shortName,
        provisions: existing.provisions.length,
        definitions: existing.definitions.length,
        status: 'cached',
      });
      totalProvisions += existing.provisions.length;
      totalDefinitions += existing.definitions.length;
      skipped++;
      processed++;
      continue;
    }

    try {
      let lawText: string;

      // Check for cached extracted text (from previous run or --skip-fetch)
      const legacySourceFile = path.join(SOURCE_DIR, `${law.id}.html`);
      if (skipFetch && fs.existsSync(sourceFile)) {
        lawText = fs.readFileSync(sourceFile, 'utf-8');
        console.log(`  Using cached ${law.shortName} (${law.code})`);
      } else if (skipFetch && fs.existsSync(legacySourceFile)) {
        lawText = fs.readFileSync(legacySourceFile, 'utf-8');
        console.log(`  Using cached (legacy) ${law.shortName} (${law.code})`);
      } else {
        // Download and extract text
        process.stdout.write(`  [${processed + 1}/${laws.length}] Fetching ${law.shortName} (${law.code})...`);
        const result = await fetchLawFile(law.code, law.docUrl, law.pdfUrl);

        if (result.status !== 200 || result.buffer.length < 1000) {
          console.log(` HTTP ${result.status} (${result.buffer.length} bytes) -- creating fallback`);
          const fallbackSeed = createFallbackSeed(law);
          fs.writeFileSync(seedFile, JSON.stringify(fallbackSeed, null, 2));
          report.push({ law: law.shortName, provisions: fallbackSeed.provisions.length, definitions: 0, status: `HTTP ${result.status} (fallback)` });
          totalProvisions += fallbackSeed.provisions.length;
          fallbacks++;
          processed++;
          continue;
        }

        console.log(` ${result.format.toUpperCase()} ${(result.buffer.length / 1024).toFixed(0)} KB`);

        // Extract text based on format
        process.stdout.write(`    Extracting text (${result.format})...`);
        const tempFile = path.join(SOURCE_DIR, `${law.id}.${result.format}`);

        if (result.format === 'doc') {
          lawText = await docToText(result.buffer, tempFile);
          docCount++;
        } else {
          lawText = await pdfToText(result.buffer, tempFile);
          pdfCount++;
        }

        // Save extracted text for --skip-fetch reuse
        fs.writeFileSync(sourceFile, lawText);
        console.log(` ${(lawText.length / 1024).toFixed(0)} KB text`);
      }

      const parsed = parseMexicanText(lawText, law);

      // If parsing returned zero provisions, create fallback
      if (parsed.provisions.length === 0) {
        console.log(`    WARNING: No provisions parsed for ${law.shortName}, creating fallback`);
        const fallbackSeed = createFallbackSeed(law);
        fs.writeFileSync(seedFile, JSON.stringify(fallbackSeed, null, 2));
        report.push({ law: law.shortName, provisions: fallbackSeed.provisions.length, definitions: 0, status: 'parse-empty (fallback)' });
        totalProvisions += fallbackSeed.provisions.length;
        fallbacks++;
      } else {
        fs.writeFileSync(seedFile, JSON.stringify(parsed, null, 2));
        totalProvisions += parsed.provisions.length;
        totalDefinitions += parsed.definitions.length;
        report.push({
          law: law.shortName,
          provisions: parsed.provisions.length,
          definitions: parsed.definitions.length,
          status: 'OK',
        });
        console.log(`    -> ${parsed.provisions.length} provisions, ${parsed.definitions.length} definitions`);
      }
    } catch (error) {
      const msg = error instanceof Error ? error.message : String(error);
      console.log(`  ERROR ${law.shortName}: ${msg}`);

      // Create fallback seed on error
      const fallbackSeed = createFallbackSeed(law);
      fs.writeFileSync(seedFile, JSON.stringify(fallbackSeed, null, 2));
      report.push({ law: law.shortName, provisions: fallbackSeed.provisions.length, definitions: 0, status: `ERROR (fallback): ${msg.substring(0, 50)}` });
      totalProvisions += fallbackSeed.provisions.length;
      fallbacks++;
      failed++;
    }

    processed++;

    // Progress log every 25 laws
    if (processed % 25 === 0) {
      const elapsed = ((Date.now() - startTime) / 1000).toFixed(0);
      const eta = ((Date.now() - startTime) / processed * (laws.length - processed) / 1000).toFixed(0);
      console.log(`\n  --- Progress: ${processed}/${laws.length} (${elapsed}s elapsed, ~${eta}s remaining) ---\n`);
    }
  }

  const totalElapsed = ((Date.now() - startTime) / 1000).toFixed(1);

  // Print summary report
  console.log(`\n${'='.repeat(80)}`);
  console.log('INGESTION REPORT');
  console.log('='.repeat(80));

  if (report.length <= 100) {
    console.log(`${'Law'.padEnd(35)} ${'Prov'.padEnd(8)} ${'Defs'.padEnd(8)} Status`);
    console.log('-'.repeat(80));

    for (const r of report) {
      console.log(
        `${r.law.substring(0, 34).padEnd(35)} ${String(r.provisions).padEnd(8)} ${String(r.definitions).padEnd(8)} ${r.status}`
      );
    }
    console.log('-'.repeat(80));
  } else {
    const okCount = report.filter(r => r.status === 'OK').length;
    const failedCount = report.filter(r => !['OK', 'cached'].includes(r.status)).length;
    const cachedCount = report.filter(r => r.status === 'cached').length;
    console.log(`  New ingestions:  ${okCount}`);
    console.log(`  Cached:          ${cachedCount}`);
    console.log(`  Failed/fallback: ${failedCount}`);
    if (failedCount > 0) {
      console.log('\n  Failed laws:');
      for (const r of report.filter(r => !['OK', 'cached'].includes(r.status))) {
        console.log(`    ${r.law.substring(0, 34).padEnd(35)} ${r.status}`);
      }
    }
  }

  console.log(`\n${'='.repeat(80)}`);
  console.log(`  Total elapsed:     ${totalElapsed}s`);
  console.log(`  Laws processed:    ${processed}`);
  console.log(`  Laws resumed:      ${resumed}`);
  console.log(`  Laws cached:       ${skipped}`);
  console.log(`  Laws fallback:     ${fallbacks}`);
  console.log(`  Laws failed:       ${failed}`);
  console.log(`  DOC extractions:   ${docCount}`);
  console.log(`  PDF extractions:   ${pdfCount}`);
  console.log(`  Total provisions:  ${totalProvisions}`);
  console.log(`  Total definitions: ${totalDefinitions}`);

  // Update census.json with ingestion stats
  if (fs.existsSync(CENSUS_PATH)) {
    const census = JSON.parse(fs.readFileSync(CENSUS_PATH, 'utf-8'));
    census.ingestion = {
      completed_at: new Date().toISOString(),
      total_laws: processed - failed,
      total_provisions: totalProvisions,
      coverage_pct: ((processed - failed) / laws.length * 100).toFixed(1),
    };

    fs.writeFileSync(CENSUS_PATH, JSON.stringify(census, null, 2) + '\n');
    console.log(`\n  Updated census.json with ingestion stats.`);
  }
}

async function main(): Promise<void> {
  const { limit, skipFetch, resume } = parseArgs();

  console.log('Mexican Law MCP -- Ingestion Pipeline');
  console.log('=====================================\n');
  console.log(`  Source:  Cámara de Diputados (diputados.gob.mx/LeyesBiblio)`);
  console.log(`  Method:  DOC download + antiword extraction (PDF fallback + pdftotext)`);
  console.log(`  License: Government Public Data (public domain)`);

  if (limit) console.log(`  --limit ${limit}`);
  if (skipFetch) console.log(`  --skip-fetch`);
  if (resume) console.log(`  --resume (skip existing seed files)`);

  const allLaws = loadLawList();
  const laws = limit ? allLaws.slice(0, limit) : allLaws;
  await fetchAndParseLaws(laws, skipFetch, resume);
}

main().catch(error => {
  console.error('Fatal error:', error);
  process.exit(1);
});
